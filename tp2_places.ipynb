{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16730144-dac6-4190-a4a7-38ce6007d9f7",
   "metadata": {},
   "source": [
    "# 0. Imports, configs y checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e3f604-b6ee-4163-9043-93eb20c3ebbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# un poco menos de warnings de tensorflow\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# de python, para especificar rutas de archivos y directorios\n",
    "from pathlib import Path\n",
    "\n",
    "# lib para trabajar con arrays\n",
    "import numpy as np\n",
    "\n",
    "# lib que usamos para mostrar las imágenes\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "# libs que usamos para construir y entrenar redes neuronales, y que además tiene utilidades para leer sets de \n",
    "# imágenes\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Convolution2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# libs que usamos para tareas generales de machine learning. En este caso, métricas\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# configuración para que las imágenes se vean dentro del notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847e7b14-1c4c-48c5-8e16-4bdfd3202a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver si detecta la GPU en caso de haberla\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "\n",
    "if gpus:\n",
    " for gpu in gpus:\n",
    "    print(\"Found a GPU with the name:\", gpu)\n",
    "else:\n",
    "    print(\"Failed to detect a GPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f481fadb-09d7-413b-9873-563ab2de9a35",
   "metadata": {},
   "source": [
    "# 1. Análisis exploratorio sobre el conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1a070c-8942-4653-a946-07afb697f6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lo vamos a estar usando seguido\n",
    "CATEGORIES = 'buildings', 'forest', 'glacier', 'mountain', 'sea', 'street'\n",
    "# configurar de acuerdo a dónde bajaron los sets de imágenes\n",
    "TRAIN_DIR = Path('./train')\n",
    "TEST_DIR = Path('./test')\n",
    "#VALIDATION_DIR = Path('./validation')\n",
    "SIZE = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2549542f-0ea2-45a0-842a-2f46408d4a27",
   "metadata": {},
   "source": [
    "Creamos datasets para Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0ef434-ed20-4da9-a492-21ff4874878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_reader = ImageDataGenerator(\n",
    "    rescale=1/255,\n",
    "    rotation_range=10,\n",
    "    #width_shift_range=0.3,\n",
    "    #height_shift_range=0.3,\n",
    "    brightness_range=(0.5, 1.5),\n",
    "    #horizontal_flip=True,\n",
    "    #vertical_flip=True,\n",
    ")\n",
    "\n",
    "READ_PARAMS = dict(\n",
    "    class_mode=\"categorical\",  # tenemos N labels, queremos tuplas de 0s y 1s indicando cuál de los labels es\n",
    "    classes=CATEGORIES,  # para usar el mismo orden en todos lados\n",
    "    target_size=(SIZE, SIZE),\n",
    "    color_mode=\"rgb\",  # queremos trabajar con las imágenes a color\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3713206-9d02-4738-ba94-cbf335b6efae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = images_reader.flow_from_directory(TRAIN_DIR, **READ_PARAMS)\n",
    "test = images_reader.flow_from_directory(TEST_DIR, **READ_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3983d81c-c2c2-4a05-aebb-2b1ad42b12a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(dataset):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    images, labels = next(dataset)\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(CATEGORIES[np.argmax(labels[i])])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609d55db-9ae9-45d1-8781-4e041cf4c570",
   "metadata": {},
   "source": [
    "## Volumetría de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654ca18e-d671-40b7-a265-ced356377053",
   "metadata": {},
   "source": [
    "El dataset de train y test cuenta con imágenes de escenas naturales de todo el mundo, train contiene 14034 imágenes y el dataset de test cuenta con 3000 imágenes, dando un total de 258 MB train y test juntos.\n",
    "Las imagenes se dividiran en 6 categorias:\n",
    "\n",
    "* \"buildings\": imagenes de edificios\n",
    "* \"forest\": imagenes de bosques en diferentes estaciones y ambientes\n",
    "* \"glacier\": imagenes de paisajes nevados\n",
    "* \"mountain\": imagenes de montañas en distintos ambientes\n",
    "* \"sea\": imagenes sobre oceanos y playas\n",
    "* \"street\": imagenes de paisaje urbano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61a7644-7852-431c-9356-5c413db2102e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_images(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef76df6f-6f2a-4d96-817f-81c88a475fe0",
   "metadata": {},
   "source": [
    "Decidimos dividir la carpeta de train para crear una carpeta de validation, mediante el uso de un script externo \"trainValidationSplit.sh\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcd974d-7dc5-403d-99d4-db6f69b257c3",
   "metadata": {},
   "source": [
    "## Estructura y tipo de las imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b7f5e6-b3a1-45f8-9206-696fcb2001cd",
   "metadata": {},
   "source": [
    "Las diversas imagenes tienen una dimension de 150x150, y todas son del tipo \"jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bfb8d5-f67c-4a1c-8ab1-10eb419b2593",
   "metadata": {},
   "source": [
    "## Distribución de la variable a predecir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0ff1e1-26e5-4ef3-82cf-b4a8c06af656",
   "metadata": {},
   "source": [
    "Primero contamos con una carpeta \"train\" que contiene carpetas por cada  categoria de imagen\n",
    "\"buildings\":  2191 imagenes\n",
    "\"forest\": 2271 imagenes\n",
    "\"glacier\": 2404 imagenes\n",
    "\"mountain\": 2512 imagenes\n",
    "\"sea\": 2274 imagenes\n",
    "\"street\": 2382 imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b303374b-6e23-48b5-935a-8356229699eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#algun grafico que muestre la distribucion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac377fd9-ae1d-487f-8b25-4a13345e42f7",
   "metadata": {},
   "source": [
    "Mostramos la distribucion del dataset de Validation: \n",
    "\n",
    "#validation.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896f6b4b-bdb6-4a12-8863-0f8ab04afc26",
   "metadata": {},
   "source": [
    "# 2. Modelado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a98829-6198-4a6b-9245-a49d265fb311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9089cab-336a-4293-850e-832a8875df7a",
   "metadata": {},
   "source": [
    "# 3. Conclusiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1555ec-db44-4d3e-80b6-7f47ee8e489a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
