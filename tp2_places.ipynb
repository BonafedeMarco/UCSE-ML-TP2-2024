{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16730144-dac6-4190-a4a7-38ce6007d9f7",
   "metadata": {},
   "source": [
    "# 0. Imports, configs y checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e3f604-b6ee-4163-9043-93eb20c3ebbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # un poco menos de warnings de tensorflow\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\" # deshabilitar la dGPU\n",
    "\n",
    "# de python, para especificar rutas de archivos y directorios\n",
    "from pathlib import Path\n",
    "\n",
    "# lib para trabajar con arrays\n",
    "import numpy as np\n",
    "\n",
    "# lib que usamos para mostrar las imágenes\n",
    "import matplotlib.pyplot as plt\n",
    "#import plotly.express as px\n",
    "\n",
    "# libs que usamos para construir y entrenar redes neuronales, y que además tiene utilidades para leer sets de \n",
    "# imágenes\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Convolution2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# pandas para el csv\n",
    "import pandas as pd\n",
    "\n",
    "# libs que usamos para tareas generales de machine learning. En este caso, métricas\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# configuración para que las imágenes se vean dentro del notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847e7b14-1c4c-48c5-8e16-4bdfd3202a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver si detecta la GPU en caso de haberla\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "\n",
    "if gpus:\n",
    " for gpu in gpus:\n",
    "    print(\"Found a GPU with the name:\", gpu)\n",
    "else:\n",
    "    print(\"Failed to detect a GPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f481fadb-09d7-413b-9873-563ab2de9a35",
   "metadata": {},
   "source": [
    "# 1. Análisis exploratorio sobre el conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1a070c-8942-4653-a946-07afb697f6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lo vamos a estar usando seguido\n",
    "CATEGORIES = 'buildings', 'forest', 'glacier', 'mountain', 'sea', 'street'\n",
    "# configurar de acuerdo a dónde bajaron los sets de imágenes\n",
    "TRAIN_DIR = Path('./train')\n",
    "TEST_DIR = Path('./test')\n",
    "VALIDATION_DIR = Path('./validation')\n",
    "SIZE = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2549542f-0ea2-45a0-842a-2f46408d4a27",
   "metadata": {},
   "source": [
    "Creamos datasets para Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0ef434-ed20-4da9-a492-21ff4874878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_reader = ImageDataGenerator(\n",
    "    rescale=1/255,\n",
    "    rotation_range=10,\n",
    "    #width_shift_range=0.3,\n",
    "    #height_shift_range=0.3,\n",
    "    brightness_range=(0.5, 1.5),\n",
    "    horizontal_flip=True,\n",
    "    #vertical_flip=True,\n",
    ")\n",
    "\n",
    "READ_PARAMS = dict(\n",
    "    class_mode=\"categorical\",  # tenemos N labels, queremos tuplas de 0s y 1s indicando cuál de los labels es\n",
    "    classes=CATEGORIES,  # para usar el mismo orden en todos lados\n",
    "    target_size=(SIZE, SIZE),\n",
    "    color_mode=\"rgb\",  # queremos trabajar con las imágenes a color\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3713206-9d02-4738-ba94-cbf335b6efae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = images_reader.flow_from_directory(TRAIN_DIR, **READ_PARAMS)\n",
    "validation = images_reader.flow_from_directory(VALIDATION_DIR, **READ_PARAMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609d55db-9ae9-45d1-8781-4e041cf4c570",
   "metadata": {},
   "source": [
    "## Volumetría de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654ca18e-d671-40b7-a265-ced356377053",
   "metadata": {},
   "source": [
    "El dataset de train y test cuenta con imágenes de escenas naturales de todo el mundo, train contiene 14034 imágenes y el dataset de test cuenta con 3000 imágenes, dando un total de 258 MB train y test juntos.\n",
    "Las imagenes se dividiran en 6 categorias:\n",
    "\n",
    "* \"buildings\": imagenes de edificios\n",
    "* \"forest\": imagenes de bosques en diferentes estaciones y ambientes\n",
    "* \"glacier\": imagenes de paisajes nevados\n",
    "* \"mountain\": imagenes de montañas en distintos ambientes\n",
    "* \"sea\": imagenes sobre oceanos y playas\n",
    "* \"street\": imagenes de paisaje urbano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3983d81c-c2c2-4a05-aebb-2b1ad42b12a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(dataset):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    images, labels = next(dataset)\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(CATEGORIES[np.argmax(labels[i])])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61a7644-7852-431c-9356-5c413db2102e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_images(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef76df6f-6f2a-4d96-817f-81c88a475fe0",
   "metadata": {},
   "source": [
    "Decidimos dividir la carpeta de train para crear una carpeta de validation, mediante el uso de un script externo \"trainValidationSplit.sh\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcd974d-7dc5-403d-99d4-db6f69b257c3",
   "metadata": {},
   "source": [
    "## Estructura y tipo de las imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b7f5e6-b3a1-45f8-9206-696fcb2001cd",
   "metadata": {},
   "source": [
    "Las diversas imagenes tienen una dimension de 150x150, y todas son del tipo \"jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bfb8d5-f67c-4a1c-8ab1-10eb419b2593",
   "metadata": {},
   "source": [
    "## Distribución de la variable a predecir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0ff1e1-26e5-4ef3-82cf-b4a8c06af656",
   "metadata": {},
   "source": [
    "Primero contamos con una carpeta \"train\" que contiene carpetas por cada  categoria de imagen\n",
    "\"buildings\":  2191 imagenes\n",
    "\"forest\": 2271 imagenes\n",
    "\"glacier\": 2404 imagenes\n",
    "\"mountain\": 2512 imagenes\n",
    "\"sea\": 2274 imagenes\n",
    "\"street\": 2382 imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b303374b-6e23-48b5-935a-8356229699eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#algun grafico que muestre la distribucion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac377fd9-ae1d-487f-8b25-4a13345e42f7",
   "metadata": {},
   "source": [
    "Mostramos la distribucion del dataset de Validation: \n",
    "\n",
    "#validation.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896f6b4b-bdb6-4a12-8863-0f8ab04afc26",
   "metadata": {},
   "source": [
    "# 2. Modelado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9f4c1b-4942-4560-9f62-7d92c0ec9a7b",
   "metadata": {},
   "source": [
    "### Funciones y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a98829-6198-4a6b-9245-a49d265fb311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# el shape de los inputs es alto_imagen * ancho_imagen * cantidad_colores\n",
    "input_shape = (SIZE, SIZE, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894b5df2-3cc8-4e3f-baf7-503b7b8071db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights_at_epochs = {}\n",
    "\n",
    "class OurCustomCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        model_weights_at_epochs[epoch] = self.model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f099e8-be65-4f6a-a751-0f6b5701972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = (\n",
    "    ('train', images_reader.flow_from_directory(TRAIN_DIR, **READ_PARAMS, batch_size=-1)),\n",
    "    ('validation', images_reader.flow_from_directory(VALIDATION_DIR, **READ_PARAMS, batch_size=-1)),\n",
    ")\n",
    "\n",
    "def show_confusion_matrix(model):\n",
    "    for dataset_name, dataset in datasets:\n",
    "        print('#' * 25, dataset_name, '#' * 25)\n",
    "    \n",
    "        batch_images, batch_labels = next(dataset)\n",
    "        \n",
    "        # super importante: usamos argmax para convertir cosas de este formato:\n",
    "        # [(0, 1, 0), (1, 0, 0), (1, 0, 0), (0, 0, 1)]\n",
    "        # a este formato (donde tenemos el índice de la clase que tiene número más alto):\n",
    "        # [1, 0, 0, 2]\n",
    "        predictions = np.argmax(model.predict(batch_images), axis=-1)\n",
    "        labels = np.argmax(batch_labels, axis=-1)\n",
    "        \n",
    "        print('Accuracy:', accuracy_score(labels, predictions))\n",
    "    \n",
    "        # graficamos la confussion matrix\n",
    "        plt.figure(figsize=(3, 4))\n",
    "            \n",
    "        plt.xticks([0, 1, 2, 3, 4, 5], CATEGORIES, rotation=45)\n",
    "        plt.yticks([0, 1, 2, 3, 4, 5], CATEGORIES)\n",
    "        plt.xlabel('Predicted class')\n",
    "        plt.ylabel('True class')\n",
    "    \n",
    "        plt.imshow(\n",
    "            confusion_matrix(labels, predictions), \n",
    "            cmap=plt.cm.Blues,\n",
    "            interpolation='nearest',\n",
    "        )\n",
    "    \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade7820d-16cc-44c9-8297-027867f3e408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_summarize(model):\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy',],\n",
    "    )\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36d0d43-648e-4586-bc0c-38f9c4aab418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_over_epochs(history):\n",
    "    plt.plot(history.history['accuracy'], label='train')\n",
    "    plt.plot(history.history['val_accuracy'], label='validation')\n",
    "    plt.title('Accuracy over train epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d85cb5c-c6d6-4fb6-99bf-b1e87f69f927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, n_epochs=5):\n",
    "    return model.fit(\n",
    "        train,\n",
    "        epochs=n_epochs,\n",
    "        batch_size=128,\n",
    "        validation_data=validation,\n",
    "        callbacks=[OurCustomCallback()]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e62c14-fddb-4697-8466-22986c73bd14",
   "metadata": {},
   "source": [
    "### Entrenamientos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157b5407-b0a7-4cb1-814f-1954ff59c96d",
   "metadata": {},
   "source": [
    "#### MLP Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fe4e79-118c-49f0-b0b1-ba7a12bb17da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP simple\n",
    "model_mlp = Sequential([\n",
    "    Input(input_shape),\n",
    "    \n",
    "    Flatten(),\n",
    "\n",
    "    Dense(500, activation='tanh'),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Dense(len(CATEGORIES), activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e61729-faa3-4a9e-8e21-e771e7fafb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_summarize(model_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78901222-ceb6-44f4-b7a0-e44218071952",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_mlp = fit_model(model_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ed99a1-1b3b-4b23-af81-5134319575b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_over_epochs(history_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3881728-4896-4047-a83f-cf41061e6915",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp.set_weights(model_weights_at_epochs[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d545195a-65b7-4c7e-875e-5ec9ee9089dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_confusion_matrix(model_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae24622-a388-41a8-8368-79e60a93a198",
   "metadata": {},
   "source": [
    "#### Convolucional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52c0397-b52d-4d96-bb59-bd60007e5569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolucional\n",
    "model_convolutional = Sequential([\n",
    "    Input(input_shape),\n",
    "\n",
    "    Convolution2D(filters=10, kernel_size=(4, 4), strides=1, activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Convolution2D(filters=10, kernel_size=(4, 4), strides=1, activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    MaxPooling2D(pool_size=(4, 4)),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(100, activation='tanh'),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Dense(len(CATEGORIES), activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313ab33c-6cd2-463e-a8ca-bda5a6d20292",
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_summarize(model_convolutional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043799d5-aa21-465c-a204-4d8e69f745ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_convolutional = fit_model(model_convolutional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2feafc-f462-4277-b688-499a14cb7b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_over_epochs(history_convolutional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3c35df-b67f-4873-b0c2-df72ee488d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_convolutional.set_weights(model_weights_at_epochs[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62d8fd8-4eb9-46a4-9a4c-dde53f248897",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_confusion_matrix(model_convolutional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb9bb39-e121-403e-84ba-36acb3b74534",
   "metadata": {},
   "source": [
    "#### Convolucional VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae4c4ec-c987-409e-b934-31a053bb3897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolucional usando convoluciones ya entrenadas de VGG16\n",
    "pretrained_model = VGG16(input_shape=input_shape, include_top=False)\n",
    "pretrained_model.trainable = False\n",
    "\n",
    "model_vgg16 = Sequential([\n",
    "    pretrained_model,\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(100, activation='tanh'),\n",
    "    Dense(100, activation='tanh'),\n",
    "    \n",
    "    Dense(len(CATEGORIES), activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c512364-8124-4a7d-b809-65bb8ed25547",
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_summarize(model_vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c6832d-cf28-4beb-b10f-7468b5f302c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_vgg16 = fit_model(model_vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba397c35-11bd-404a-a9de-4b6b9436e9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_over_epochs(history_vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbb04de-04e2-4619-8cb9-6d78821e2124",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg16.set_weights(model_weights_at_epochs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb80afe9-c365-4740-85ce-83605b56b62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_confusion_matrix(model_vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c7e780-4cb8-43b3-82a2-3130d82010db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# copia del contenido de la función de la celda anterior para debugging\n",
    "\n",
    "datasets = (\n",
    "    ('train', images_reader.flow_from_directory(TRAIN_DIR, **READ_PARAMS, batch_size=-1)),\n",
    "    ('validation', images_reader.flow_from_directory(VALIDATION_DIR, **READ_PARAMS, batch_size=-1)),\n",
    ")\n",
    "\n",
    "for dataset_name, dataset in datasets:\n",
    "    print('#' * 25, dataset_name, '#' * 25)\n",
    "\n",
    "    batch_images, batch_labels = next(dataset)\n",
    "    \n",
    "    # super importante: usamos argmax para convertir cosas de este formato:\n",
    "    # [(0, 1, 0), (1, 0, 0), (1, 0, 0), (0, 0, 1)]\n",
    "    # a este formato (donde tenemos el índice de la clase que tiene número más alto):\n",
    "    # [1, 0, 0, 2]\n",
    "    predictions = np.argmax(model_convolutional.predict(batch_images), axis=-1)\n",
    "    labels = np.argmax(batch_labels, axis=-1)\n",
    "    \n",
    "    print('Accuracy:', accuracy_score(labels, predictions))\n",
    "\n",
    "    # graficamos la confussion matrix\n",
    "    plt.figure(figsize=(3, 4))\n",
    "        \n",
    "    plt.xticks([0, 1, 2, 3, 4, 5], CATEGORIES, rotation=45)\n",
    "    plt.yticks([0, 1, 2, 3, 4, 5], CATEGORIES)\n",
    "    plt.xlabel('Predicted class')\n",
    "    plt.ylabel('True class')\n",
    "\n",
    "    plt.imshow(\n",
    "        confusion_matrix(labels, predictions), \n",
    "        cmap=plt.cm.Blues,\n",
    "        interpolation='nearest',\n",
    "    )\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9089cab-336a-4293-850e-832a8875df7a",
   "metadata": {},
   "source": [
    "# 3. Conclusiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1555ec-db44-4d3e-80b6-7f47ee8e489a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ad81b5d-6cae-410d-9e66-f55f40d99232",
   "metadata": {},
   "source": [
    "# 4. Competencia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3a84b6-bdc4-4ce3-a31c-33c5071ded18",
   "metadata": {},
   "source": [
    "Creación de archivos CSV para la submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ba1ed5-3983-4004-b733-44e0875fa83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_FILENAME = \"ConvolutionalDefault\"\n",
    "MODEL = model\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for image in os.listdir(TEST_DIR):\n",
    "    image_path = os.path.join(TEST_DIR, image)\n",
    "    image_array = img_to_array(load_img(image_path, target_size=(SIZE, SIZE)))\n",
    "    images.append(image_array)\n",
    "\n",
    "inputs = np.array(images) / 255.0\n",
    "\n",
    "predictions = MODEL.predict(inputs)\n",
    "\n",
    "for i, filename in enumerate(os.listdir(TEST_DIR)):\n",
    "    predicted_label = CATEGORIES[np.argmax(predictions[i])]\n",
    "    labels.append([filename, predicted_label])\n",
    "\n",
    "df = pd.DataFrame(labels, columns=[\"ID\", \"Label\"])\n",
    "df.to_csv(CSV_FILENAME+\".csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
